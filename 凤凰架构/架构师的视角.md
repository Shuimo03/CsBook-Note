# 远程服务调用(RPC)

进程间的通信方式：

+ 管道或者具名管道：可通过管道在进程间传递少量的字符流或字节流。普通管道只用于有亲缘关系进程（由一个进程启动的另外一个进程）间的通信，具名管道摆脱了普通管道没有名字的限制，除具有管道所有的功能外，它还允许无亲缘关系进程间的通信。
+ 信号：信号用于通知目标进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程自身。
+ 信号量：信号量用于两个进程之间同步协作手段，它相当于操作系统提供的一个特殊变量，程序可以在上面进行`wait()`和`notify()`操作。
+ 消息队列：以上三种方法只适合传递少量信息，POSIX 标准中定义了消息队列用于进程间数据量较多的通信。
+ 共享内存：允许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信形式。
+ 套接字接口：消息队列和共享内存只适合单机多进程间的通信，套接字接口是更为普适的进程间通信机制，可用于不同机器之间的进程通信。
+ RPC

### 通信成本

# REST 设计风格

REST 与 RPC 在思想上差异的核心是抽象的目标不一样，即面向资源的编程思想与面向过程的编程思想两者之间的区别。

**TODO 三种风格的区别**

+ 资源
+ 表征
+ 状态
+ 转移
+ 统一接口
+ 超文本驱动
+ 自描述信息

### REST的例子

### REST的不足

+ 面向资源编程思想只适合做CRUD，面向过程，面向对编程才能处理真正复杂的业务逻辑。
+ REST 与 HTTP 完全绑定，不适合应用于要求高性能传输的场景中。
+ REST 不利于事务支持。
+ REST 没有传输可靠性支持。
+ REST 缺乏对资源进行“部分”和“批量”的处理能力。

## 事务处理

事务的经典理论ACID:

+ **原子性**（**A**tomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。
+ **一致性**（**C**onsistency）:
+ **隔离性**（**I**solation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。
+ **持久性**（**D**urability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。

事务的概念虽然最初起源于数据库系统，但是今天已经不局限于数据库本身了，所有需要保证数据一致性的应用场景，包括但不限于数据库、事务内存、缓存、消息队列、分布式存储等等。都有可能使用到事务。

## 本地事务

本地事务是最基础的一种事务解决方案，只适用于单个服务使用单个数据源的场景。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程当中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作。

**TODO ARIES理论**

### 实现原子性和持久性

数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，只存储在内存中的数据，一旦遇到应用程序忽然崩溃，或者数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等情况就会丢失。

实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。

假设一个场景，从线上书店(原文中是Fenix's Bookstore)购买一本书，需要修改三个数据：

+ 在用户账户中减去货款
+ 在商家账户中增加货款
+ 在商品仓库中标记一本书为配送状态

因为存在写入中间状态，所以可能会发生以下情况：

+ 未提交事务，写入后崩溃：程序还没修改完三个数据，但数据库已经将其中一个或两个数据的变动写入磁盘，此时出现崩溃，一旦重启之后，**数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。**
+ 已提交事务，写入前崩溃：程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，**一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。**

**TODO**

+ 崩溃恢复
+ 追加写入(以日志的形式)
+ NO-FORCE 策略
+ 提前写入(Write-Ahead)

### Shadow Paging(影子分页)

对数据的变动会写到硬盘的数据中，**但并不是直接就地修改原先的数据，而是先将数据复制一份副本，保留原数据，修改副本数据。**在事务过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是去修改数据的引用指针，将引用从原数据改为新复制出来修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作可以认为在硬件上保证了不会出现“改了半个值”的现象。所以 Shadow Paging 也可以保证原子性和持久性。Shadow Paging 实现事务要比 Commit Logging 更加简单，但涉及隔离性与并发锁时，Shadow Paging 实现的事务并发能力就相对有限，因此在高性能的数据库中应用不多。

简单来说就是，先把要改动的数据复制一份，然后对复制后的数据进行操作，如果操作成功了就会修改指针指向原来的数据。

这样就算出现崩溃，也对原数据没有影响。

### Commit Logging

日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场、继续修改数据即可，这保证了持久性；其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，整个事务就像完全没好有发生过一样，这保证了原子性。

但是，Commit Logging 存在一个巨大的先天缺陷：**所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后。在此之前，即使磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大，占用了大量的内存缓冲区**，无论有何种理由，都决不允许在事务提交之前就修改磁盘上的数据，这一点是 Commit Logging 成立的前提，却对提升数据库的性能十分不利。

Commit Logging 允许 NO-FORCE，但不允许 STEAL。

### Write-Ahead Logging

Write-Ahead Logging先把任意时刻写入的变动数据，按照事务提交时间点作为分解，划分为 FORCE 和 STEAL 两类情况。

+ FORCE：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。
+ STEAL ：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。

**Write-Ahead Logging 允许 NO-FORCE，也允许 STEAL**，它给出的解决办法是增加了另一种被称为 Undo Log 的日志类型，当变动数据写入磁盘前，必须先记录 Undo Log(回滚日志)，注明修改了哪个位置的数据、从什么值改成什么值，等等。以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除。

Write-Ahead Logging在崩溃恢复时会执行以下三个阶段的操作：

+ 分析阶段(Analysis)：
+ 重做阶段(Redo)：
+ 回滚阶段(Undo)：

重做阶段和回滚阶段的操作都应该设计为幂等的。

### 实现隔离性

隔离性保证了每个事务各自读、写的数据互相独立，不会彼此影响。如果没有并发，所有事务全都是串行的，那就不需要任何隔离，或者说这样的访问具备了天然的隔离性。

如何在并发情况下实现串行的数据访问？可以通过下面三种方式实现：

+ 写锁：如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。
+ 读锁：多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。
+ 范围锁：对于某个范围直接加排他锁，在这个范围内的数据不能被写入。

**TODO**

+ 可串行化
+ 可重复读
+ 读已提交
+ 读未提交
+ Two-Phase Lock 2PL
+ 幻读
+ 不可重复读问题(Non-Repeatable Reads)
+ 多版本并发控制(MVCC)

## 全局事务

+ DTP模型
+ CAP理论
+ 2PC
+ 拜占庭将军问题
+ FLP不可能原理
+ 3PC协议

### 2PC协议

2PC分为两个阶段：

+ 准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。
+ 提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。

2PC能够保证成功一致性的情况还需要一些前提条件：

+ 必须假设网络在提交阶段的短时间内可靠，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，它的目标并不是解决类似于拜占庭将军问题的问题，两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短。
+ 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。

### 2PC的缺点

+ 单点问题：
+ 性能问题
+ 一致性风险

### 3PC协议

## 问题思考

+ 两个进程通信，谁作为服务端，谁作为客户端？
+ 怎样进行异常处理？异常该如何让调用者获知？
+ 服务端出现多线程竞争之后怎么办？
+ 如何提高网络利用的效率，譬如连接是否可被多个请求复用以减少开销？是否支持多播？
+ 参数、返回值如何表示？应该有怎样的字节序？
+ 如何保证网络的可靠性？譬如调用期间某个链接忽然断开了怎么办？
+ 发送的请求服务端收不到回复该怎么办？