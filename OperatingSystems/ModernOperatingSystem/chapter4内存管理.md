## 内存管理

### 虚拟内存

在了解虚拟内存之前，我们先假设没有虚拟内存是什么样子的，在没有虚拟内存的情况下，所有的程序都是直接访问物理内存。

操作系统为了让这些应用共享物理内存，有两种方式，最简单的一种是当一个程序A在运行的时候就让它访问所有的资源，如果需要切换到另外一个程序B的时候，操作系统就把当前程序A的内存数据保存到存储设备上(比如磁盘)，然后把程序B的数据从存储设备加载到内存中。

但是这样的话，因为存储设备的读写速度很慢，就会导致切换程序的时间开销很大。另外一种方式，就是让每个程序独立使用物理内存的一部分，数据一直保存在内存里面，这样的好处就是不需要切换设备了，并且速度也比第一种快。

这样做会带来两个缺点：

+ 程序之间没有隔离性，比如程序A在运行的过程中可能会意外的用到程序B的物理内存，从而导致运行错误。
+ 无法保证应用程序的可用地址空间时连续的和统一的，增加了程序编写和编译的复杂性。

所以为了解决以上问题，能够让操作系统高效又安全的共用内存，**操作系统添加了一个新的抽象概念：虚拟内存。应用程序面向虚拟内存而不再面向物理内存，运行时只使用虚拟地址，CPU负责把虚拟地址翻译成物理地址，操作系统需要做的是把虚拟地址翻译到物理地址**。

虚拟内存带来的好处如下：

+ 提高内存资源的利用率；每个程序都认为自己是占用一个物理内存。
+ 提高了程序之间的隔离性，每个程序的虚拟地址空间是统一的，连续的，从而降低编程的复杂度。

### 虚拟内存设计的三个目标

+ 高效性
+ 安全性
+ 透明性

操作系统再分配物理内存的时候，需要保证物理内存的利用率，还需要保证分配物理内存的速度。

### 虚拟地址

### 物理地址

物理内存可以看作是一个大的数组，其中每个数组下标都可以通过唯一的地址进行访问，这个地址就是物理地址。在应用程序或者操作系统运行的过程中，CPU通过总线发送访问物理地址的请求，从内存中读取数据或者写入数据。

### 内存管理单元(Memory Management Unit MMU)

MMU负责虚拟地址到物理地址的转换。

### 转址旁路缓存(Translation Lookaside Buffer TLB)

TLB属于MMU内部单元，TLB缓存了虚拟页号到物理页号的映射关系，**可以把TLB看作是存储键值对的哈希表，其中键是虚拟页号，值是物理页号。**

多级页表结构虽然可以压缩页表的大小，但是也会导致地址翻译时长的增加。具体来说，多级页表结构能够让MMU在翻译虚拟地址的过程中需要多次查找多个页表页中的页表项，一次地址翻译可能会导致多次的物理内存访问，**所以为了减少地址翻译的访存次数，MMU引入了TLB。**

**MMU会先把虚拟号作为键去查询TLB中的缓存项，如果找到了则直接获取对应的物理页号，不需要在查询页表。**通过TLB能够直接完成地址翻译的过程被称为TLB命中，反之被称为TLB未命中。

一般来说，TLB硬件采用了分层的架构，如下：

+ L1：数据TLB和指令TLB，分别用于缓存数据和指令的地址翻译。
+ L2：不区分数据和指令。

### 分段机制

MMU将虚拟地址翻译成物理地址的主要两种手段是：

+ 分段机制
+ 分页机制

在分段机制下，操作系统以段(一段连续的物理内存)的形式管理/分配物理内存，**应用程序的虚拟地址空间是由若干个不同大小的段组成的，比如代码段，数据段等等，每一段都是不定长的。**

CPU访问虚拟地址空间某一个段的时候，MMU会通过查询段表来得到段对应的物理内存区域，虚拟地址由两部分组成：

+ 段号：代表着该虚拟地址属于整个虚拟地址空间中的那一段。
+ 段内地址(段内偏移)：相对于该段起始地址的偏移量。

段表存储着一个虚拟地址空间中每一个分段的信息，在分段机制下，不仅虚拟内存空间被划分成不同的段，物理内存也以段作为单位进行分配。在虚拟地址空间中，**相邻的段对应的物理内存中的段是不可以相邻的。**

所以操作系统能够实现物理资源的离散分配，但是这样会导致物理内存上出现外部碎片，**也就是段与段之间留下的碎片空间，从而造成物理内存资源利用率降低。**

举个简单的例子，物理内存有6个G，目前被划成4个段进行分配：

+ 第一段0-2G
+ 第二段2-3G
+ 第三段3-4G
+ 第四段5-6G

### 分页机制

分页机制的基本思想是把应用程序的虚拟地址划分成连续等长的虚拟页，同时物理内存也被划分成连续的，等长的物理页。虚拟页和物理页的页长是固定且相等的。

从而使得操作系统能够很方便的为每个应用程序构造页表，和段表的功能一样，也就是把虚拟地址映射到物理地址上一样。

逻辑上，分页机制下的虚拟地址分为两部分：

+ 虚拟页号
+ 页内偏移量

分页机制按照固定页大小分配物理内存，使得物理内存资源容易管理，可以有效的避免分段机制中出现的外部碎片问题。

## 多级页表设计

多级页表的设计是为了解决单页表的太大的问题，假设一个64位虚拟地址的空间，它的页表有4KB大小，页表中每一项大小有8字节，用来存放物理地址。那一张也表的大小就是2^64 / 4KB *8字节，也就是33 554 432GB。

在使用多页表的时候，一个虚地址依然包括虚拟页号和页内偏移量，其中虚拟页号被进一步的划分成K个部分，虚拟页号i对应该虚拟地址所在的第i级页表中的索引。

### 换页机制

如果虚拟页没有被分配使用的话，那在页表中自然也没有相对应的物理页映射，换一种说话，虚拟页被分配使用之后，在页表中依然可能没有映射到物理页。

打个比方，电脑内存一共4GB物理内存，edge占用了2GB，打开IDE和虚拟机又占了5GB，按照直觉来看这应该是打不开的。因为加起来一共7GB，而电脑内存一共才4GB。

那为什么会最后会被打开呢？因为虚拟内存的透明性。虚拟内存中的换页机制就是为了透明满足这样的场景所设计的，这个机制的思想是：当物理内存容量不足的时候，操作系统就应该把若干物理页的内容写到类似于磁盘这种容量大并且更加便宜的存储设备中，然后可以回收这些物理页并继续使用了。

### 缺页异常

缺页异常和换页机制是密不可分的，缺页异常是换页机制能够工作的的前提，当应用程序访问已经分配但是没有映射到物理内存的虚拟页的时候，就会发生缺页异常。

## 页替换策略

当需要分配物理页的时候，假设空闲的物理页已经用完或者小于某个阈值的时候，操作系统就会根据页替代策略选择一个或者一些物理页换出到磁盘以便让出空间。

当被换出的内存页在被访问到的时候，就必须从新从磁盘换入到内存中，这样一来一回的非常浪费时间。所以，页替代策略的出现可以降低这种耗时行为。

### 常用页替代策略

+ MIN策略/OPT策略(理论可以)
+ FIFO策略
+ second Chance策略
+ LRU策略
+ MRU策略
+ 时钟算法策略

### FIFO策略

FIFO策略是最简单的页替换策略之一，它的时间开销很低，该策略优先选择最先换入的页进行换出，操作系统维护一个队列用来记录换入内存的物理页号。

## 虚拟功能

### 共享内存

共享内存允许不同的程序共享同一个物理页，假设应用程序A的虚拟页映射到物理页P，应用程序B的虚拟页也映射到物理页P，就说明两个应用程序共享一个物理页P。

它们可以看到对方相同的修改内容，共享内存的一个基本用途是可以让不同的应用程序之间相互通信传输数据，除此之外，还衍生出了写时拷贝和内存去重等方法。

### 写时拷贝

写时拷贝技术一方面能够节约物理内存资源，比如不同的应用程序以写时拷贝的方式映射相同的动态链接库，另一方面可以让父子程序以只读的方式共享全部内存数据，避免内存拷贝操作带来的时间和空间开销。

### 内存去重

### 内存压缩

### 大页

## 物理内存分配与管理

### 目标和评价维度

### 内存碎片

内存碎片是指没有办法被利用起来的内存，会直接导致内存资源利用率下降，内存碎片又分为三种：

+ 外部碎片
+ 内部碎片

外部碎片通常会在多次分配和回收之后，物理内存上空闲的部分处于离散分布状态，这个时候有可能会出现一个内存分配请求，其请求的内存大小大于任意一个单独的空闲部分，却小于空闲部分的总和。

换句话来说，就是系统中有足够的空闲内存，但是没有办法满足这个请求。这些无法使用的空闲物理内存被称为外部碎片。

一种直观的解决外部碎片，是把物理内存以固定大小(能够满足最大分配请求)划成若干块，然后每次使用一块服务就分配一块请求，但是这样只解决了外部内存碎片，还有内部内存碎片没有解决。

当分配的空间大于实际分配请求所需要的空间时，就会造成内存浪费，这种浪费就是内存碎片。

### 伙伴系统

### SLAB分配器

### SLUB分配器

## 思考题

+ 当多个应用程序同时运行的时候，操作系统如何让它们共同使用物理内存资源？
+ 为什么需要虚拟地址？
+ 分段和分页有什么区别？
+ 如何保证TLB中内容和当前页表内容的一致性？
+ 被分配使用的虚拟页在页表中一定有对应的物理页映射吗？
+ 如何使用虚拟内存实现内存共享？
+ 什么是写时拷贝？写时拷贝如何实现的？
+ 如何利用虚拟内存抽象节约物理内存？内存去重和内存压缩？
+ 什么是大页？为什么要使用大页？